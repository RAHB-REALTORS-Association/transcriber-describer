<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- Bootstrap CSS -->
    <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" rel="stylesheet">

    <title>Transcriber-Describer</title>
  </head>
  <body>
    <div class="container my-4">
        <div id="readmeContent"></div>
    </div>

    <!-- Optional JavaScript; choose one of the two! -->
    <!-- Option 1: Bootstrap Bundle with Popper -->
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.bundle.min.js"></script>

    <h1>Transcriber-Describer</h1>

    <p>This project transcribes audio from video files and generates descriptions from the transcriptions. It uses OpenAI's <b>Whisper API</b> for transcription and the <b>ChatGPT-3.5-turbo</b> model for generating descriptions. The user can opt to use a local model for both tasks if desired. The tool also supports extracting a specific duration from the start of the video and controlling the bitrate of the audio.</p>
    
    <h3>How to Run</h3>
    <p>You can run the main Python script from the terminal with several optional flags:</p>
    
    <pre>
    <code>
    python main.py /path/to/video/folder --local --local-transcribe --local-describe --time &lt;seconds&gt; --bitrate &lt;bitrate&gt; --overwrite
    </code>
    </pre>
    
    <ul>
    <li>The <code>--local</code> flag uses local versions of both the transcribe and describe functions.</li>
    <li>The <code>--local-transcribe</code> flag uses the local version of the transcribe function.</li>
    <li>The <code>--local-describe</code> flag uses the local version of the describe function.</li>
    <li>The <code>--time</code> flag sets the duration in seconds of the video to transcribe.</li>
    <li>The <code>--bitrate</code> flag sets the bitrate for the extracted audio.</li>
    <li>The <code>--overwrite</code> flag enables overwriting of existing audio, transcript, or description files.</li>
    </ul>
    
    <p>If you just want to process the video files in a directory without using any flags, you can do so:</p>
    
    <pre>
    <code>
    python main.py /path/to/video/folder
    </code>
    </pre>
    
    <h3>Setting up your OpenAI API credentials:</h3>
    
    <ol>
    <li>Sign up for an OpenAI account if you don't already have one.</li>
    <li>Navigate to the API section of the OpenAI Dashboard.</li>
    <li>Generate a new API key by clicking the "Create API Key" button.</li>
    <li>Securely store your API Key.</li>
    <li>Set your API Key as an environment variable in your system: <code>export OPENAI_API_KEY="your-api-key"</code>.</li>
    </ol>
    
    <h3>Installing Dependencies</h3>
    <p>This project uses the <code>openai</code>, <code>moviepy</code>, <code>pydub</code>, and <code>pysubs2</code> libraries. You can install them using pip:</p>
    
    <pre>
    <code>
    pip install openai moviepy pydub pysubs2
    </code>
    </pre>
  </body>
</html>
